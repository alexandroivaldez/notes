# AWS Bedrock

Bedrock is a serverless and fully managed service from AWS that makes foundation models accessible through an API.

AWS CLI -> Bedrock API ->  Foundation Model

## Supported FM Models from AWS Bedrock
- **Amazon Titan**
    - General purpose model
- **Jurassic-2**
    - Multilingual LLM for text generation
- **Claude**
    - LLM for conversations, Q&A and workflow automation.
- **Stable Diffusion**
    - Generates images, art, etc.

## Custom Models

Allows you to fine tune and train foundational models. The models allowed are selectd by AWS.

You need to purchase a provisioned throughput, a set pricing plan.

## Architecture

**Runtime Inference** - Determines which FM is being requested by the user.

**Prompt History Store** - Stores queries asked to the FM. Only stores the queries made by the console.

## Inference Paramters

Inference parametes influence the response generated by the model.

### Randomness and Diversity

1. **Temperature**
    - Controls the level of uncertainty or randomness in generating predictions.

2. **Top K**
    - Where the models cease to select words, known as the cutoff point.

3. **Top P**
    - Choices based on the cumulative sum of their probabilities.

### Length

1. **Length**
    - Controls the length of the generated response.

2. **Max Length**
    - Maximum number of tokens.

3. **Stop Sequence**
    - The keyword that stops the generation of tokens.

### Repetition

1. **Repetition**
    - Helps control repetiton in generated responses.

2. **Presence Penalty,Count Penalty and Frequence Penalty**
    - Reduce the frequence of repetitions. Each has their own specialization.

5. **Penalize Special Tokens**
    - Reduce the chance of special characters.

## Pricing

### On Demand

You pay for what you use.

### Provisioned Throughput

A pricing plan for a specific time commitment.